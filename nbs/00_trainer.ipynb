{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import jax, jax.numpy as jnp, jax.random as jrand\n",
    "import haiku as hk\n",
    "import optax\n",
    "import chex\n",
    "from dataclasses import dataclass\n",
    "import functools as ft\n",
    "from typing import Callable, Tuple, Any, Sequence, Iterable, Mapping, Dict, List, NamedTuple\n",
    "import copy\n",
    "# from haiku_trainer.callbacks import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TrainState(NamedTuple):\n",
    "    epoch: int\n",
    "    step: int\n",
    "    params: hk.Params\n",
    "    state: hk.State\n",
    "    opt_state: optax.OptState\n",
    "    next_key: jrand.PRNGKey\n",
    "    logs: dict = None\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        return self.params is None and self.opt_state is None\n",
    "    \n",
    "    @classmethod\n",
    "    def create_empty(cls) -> TrainState:\n",
    "        return cls(\n",
    "            epoch=0, step=0, \n",
    "            params=None, state=None, opt_state=None, \n",
    "            next_key=None, logs=None\n",
    "        )\n",
    "\n",
    "    def __eq__(self, compare: TrainState) -> bool:\n",
    "        return (self.epoch == compare.epoch) and (self.step == compare.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Trainer:\n",
    "    transformed: hk.TransformedWithState | hk.MultiTransformedWithState\n",
    "    optimizers: optax.GradientTransformation | Sequence[optax.GradientTransformation]\n",
    "    rng_key: jrand.PRNGKey = None\n",
    "\n",
    "    # callback functions\n",
    "    callbacks: Sequence[Callback] = None\n",
    "    step_fn: StepFn = None\n",
    "\n",
    "    # trainer configs\n",
    "    lr: float = 1e-3\n",
    "    n_epochs: int = 1\n",
    "\n",
    "    @property\n",
    "    def train_state(self) -> TrainState:\n",
    "        \"\"\"Returns the current train state.\"\"\"\n",
    "        return self._train_state\n",
    "\n",
    "    @ft.cached_property\n",
    "    def num_train_batches(self) -> int:\n",
    "        \"\"\"Returns the number of training batches of each epoch.\"\"\"\n",
    "        loader = getattr(self, '_train_dataloader', None)\n",
    "        if loader is None:  return 0\n",
    "        else:               return len(loader)\n",
    "    \n",
    "    @property\n",
    "    def num_train_steps(self) -> int:\n",
    "        \"\"\"Returns the number of training steps.\"\"\"\n",
    "        return self.n_epochs * self.num_train_batches\n",
    "    \n",
    "    @property\n",
    "    def num_val_batches(self) -> int:\n",
    "        \"\"\"Returns the number of validation batches of each epoch.\"\"\"\n",
    "        loader = getattr(self, '_val_dataloader', None)\n",
    "        if loader is None:  return 0\n",
    "        else:               return len(loader)\n",
    "    \n",
    "    @property\n",
    "    def num_val_steps(self):\n",
    "        \"\"\"Returns the number of validation steps.\"\"\"\n",
    "        return self.n_epochs * self.num_val_batches\n",
    "\n",
    "    def _initialize_properties(self):\n",
    "        \"\"\"Initializes `train_state`.\"\"\"\n",
    "        if getattr(self, '_train_state', None) is None:\n",
    "            self._train_state = TrainState.create_empty()\n",
    "    \n",
    "    def _initialize_key(self):\n",
    "        \"\"\"Initialize the `rng_key`.\"\"\"\n",
    "        if self.rng_key is None:    return jrand.PRNGKey(42) # TODO: use global\n",
    "        else:                       return self.rng_key\n",
    "\n",
    "    def _initialize_callbacks(self):\n",
    "        \"\"\"Initializes the callbacks.\"\"\"\n",
    "        if self.callbacks is None:\n",
    "            self.callbacks = CallbackList()\n",
    "        elif isinstance(self.callbacks, CallbackList):\n",
    "            self.callbacks = self.callbacks\n",
    "        elif isinstance(self.callbacks, Sequence):\n",
    "            self.callbacks = CallbackList(self.callbacks)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid callbacks. Expected `CallbackList` or `Sequence[Callback]`.\")\n",
    "\n",
    "        self.callbacks.init_trainer(self)\n",
    "\n",
    "    def _initialize_step_fn(self):\n",
    "        \"\"\"Initializes step fns.\"\"\"\n",
    "        if self.step_fn is None:\n",
    "            self.step_fn = DefaultStepFn(trainer=self)\n",
    "        else:\n",
    "            if isinstance(self.step_fn, StepFn):\n",
    "                self.step_fn.init_trainer(self)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid `Trainer.step_fn`. Expected `StepFn`, but got `{type(self.step_fn)}`.\")\n",
    "    \n",
    "    def _initialize(self):\n",
    "        \"\"\"Initializes the trainer.\"\"\"\n",
    "        self._initialize_properties()\n",
    "        self._initialize_key()\n",
    "        self._initialize_callbacks()\n",
    "        self._initialize_step_fn()\n",
    "\n",
    "    def _update_loader(self, loader_name: str, loader=None):\n",
    "        if getattr(self, loader_name, None) is None:\n",
    "            setattr(self, loader_name, loader)\n",
    "        if loader is not None:\n",
    "            setattr(self, loader_name, loader)\n",
    "    \n",
    "    def _initialize_loaders(\n",
    "        self, \n",
    "        train_dataloader, \n",
    "        val_dataloader=None, \n",
    "        test_dataloader=None\n",
    "    ):\n",
    "        \"\"\"Initialize and hook dataloaders to the trainer.\"\"\"\n",
    "        self._update_loader('_train_dataloader', train_dataloader)\n",
    "        self._update_loader('_val_dataloader', val_dataloader)\n",
    "        self._update_loader('_test_dataloader', test_dataloader)\n",
    "        \n",
    "    def _run_callbacks(\n",
    "        self, \n",
    "        hook_name: str, # Should be \"on_{train/val}_{epoch/batch}_{begin/end}\"\n",
    "        **cb_kwargs # kwargs for the callback function\n",
    "    ):\n",
    "        \"\"\"Runs the callback functions for the given hook.\n",
    "        Note that callback functions do not change the `train_state`.\n",
    "        \"\"\"\n",
    "        hook_fn = getattr(self.callbacks, hook_name, None)\n",
    "        if hook_fn is not None:\n",
    "            hook_fn(self.train_state, **cb_kwargs)\n",
    "\n",
    "    def _run_step_fn(\n",
    "        self, \n",
    "        step_name: str, \n",
    "        validate: bool = False,\n",
    "        **fn_kwargs # kwargs for the step function\n",
    "    ):\n",
    "        \"\"\"Runs the step function for the given step name.\n",
    "        Note that step functions change the `train_state`.\n",
    "        \"\"\"\n",
    "        step_fn = getattr(self.step_fn, step_name)\n",
    "        train_state = step_fn(self.train_state, **fn_kwargs)\n",
    "\n",
    "        if validate and train_state == self.train_state:\n",
    "            raise ValueError(f\"Train state is not updated after `{step_name}`.\")\n",
    "        self.update_train_state(train_state)\n",
    "\n",
    "    def update_train_state(self, train_state: TrainState = None, **kwargs):\n",
    "        \"\"\"Updates the `train_state`.\"\"\"\n",
    "        if train_state is None and kwargs == {}:\n",
    "            raise ValueError(\"Either `train_state` or `kwargs` must be provided.\")\n",
    "        if train_state is None:\n",
    "            train_state = self.train_state._replace(**kwargs)\n",
    "        self._train_state = train_state\n",
    "\n",
    "    def fit(self, train_dataloader, val_dataloader=None):\n",
    "        self._initialize()\n",
    "        self._initialize_loaders(train_dataloader, val_dataloader)\n",
    "        \n",
    "        self._run_callbacks(\"on_train_begin\")\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self._run_callbacks(\"on_epoch_begin\")\n",
    "            for batch in train_dataloader:\n",
    "                self._run_callbacks(\"on_train_batch_begin\")\n",
    "                # Initialize the train state if it is not initialized\n",
    "                if self.train_state.is_empty():\n",
    "                    self._run_step_fn(\"init_step\", batch=batch)\n",
    "                self._run_step_fn(\"train_step\", batch=batch)\n",
    "                self._run_callbacks(\"on_train_batch_end\")\n",
    "            self._run_callbacks(\"on_epoch_end\")\n",
    "\n",
    "            if val_dataloader is not None:\n",
    "                self._run_callbacks(\"on_val_begin\")\n",
    "                for batch in val_dataloader:\n",
    "                    self._run_callbacks(\"on_val_batch_begin\")\n",
    "                    self._run_step_fn(\"val_step\", batch=batch)\n",
    "                    self._run_callbacks(\"on_val_batch_end\")\n",
    "                self._run_callbacks(\"on_val_end\")\n",
    "\n",
    "            # self._run_callbacks(\"on_epoch_end\")\n",
    "            self._run_step_fn(\"epoch_step\", batch=None)\n",
    "        \n",
    "        self._run_callbacks(\"on_train_end\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class StepFn:\n",
    "    def __init__(self, trainer: Trainer=None, *args, **kwargs) -> None:\n",
    "        if trainer is not None:\n",
    "            self.init_trainer(trainer)\n",
    "\n",
    "    def init_trainer(self, trainer: Trainer):\n",
    "        self._trainer = trainer\n",
    "\n",
    "    @property\n",
    "    def trainer(self): return self._trainer\n",
    "\n",
    "    @property\n",
    "    def transformed(self): return self.trainer.transformed\n",
    "\n",
    "    forward = transformed\n",
    "    \n",
    "    @property\n",
    "    def optimizers(self): return self.trainer.optimizers\n",
    "\n",
    "    def init_step(self, train_state: TrainState, batch: Tuple[jax.Array, ...]) -> TrainState:\n",
    "        key1, next_key = jrand.split(self._init_key())\n",
    "        \n",
    "        params, state = self._init_params_and_state(key1, batch[0])\n",
    "        opt_states = self._init_opt_state(params)\n",
    "        return TrainState(\n",
    "            epoch=0, step=0, params=params, state=state, \n",
    "            opt_state=opt_states, next_key=next_key,\n",
    "        )\n",
    "    \n",
    "    def epoch_step(self, train_state: TrainState, batch=None) -> TrainState:\n",
    "        return train_state._replace(epoch=train_state.epoch+1)\n",
    "    \n",
    "    def train_step(self, train_state: TrainState, batch: Tuple[jax.Array, ...]) -> TrainState:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def val_step(self, train_state: TrainState, batch: Tuple[jax.Array, ...]) -> TrainState:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def _init_key(self):\n",
    "        if self.trainer.rng_key is None:\n",
    "            return jrand.PRNGKey(0)\n",
    "        elif isinstance(self.trainer.rng_key, jrand.PRNGKey):\n",
    "            return self.trainer.rng_key\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid rng_key. Expected `jax.random.PRNGKey`.\")\n",
    "\n",
    "    def _init_params_and_state(self, key: jrand.PRNGKey, xs: jax.Array):\n",
    "        params, state = self.transformed.init(key, xs)\n",
    "        return params, state\n",
    "\n",
    "    def _init_opt_state(self, params: hk.Params):\n",
    "        if isinstance(self.optimizers, optax.GradientTransformation):\n",
    "            return self.optimizers.init(params) \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid optimizers. Expected `optax` optimizers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DefaultStepFn(StepFn):\n",
    "\n",
    "    @ft.partial(jax.jit, static_argnums=(0,))\n",
    "    def train_step(self, train_state: TrainState, batch: Tuple[jax.Array, ...]) -> TrainState:\n",
    "        def loss_fn(params: hk.Params):\n",
    "            logits, new_state = self.transformed.apply(\n",
    "                params, state,\n",
    "                rng_key, # <== rng\n",
    "                inputs, is_training=True # <== inputs\n",
    "            )\n",
    "            loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "            return (loss, new_state)\n",
    "        \n",
    "        inputs, labels = batch\n",
    "        rng_key, next_key = jrand.split(train_state.next_key)\n",
    "        state = train_state.state\n",
    "        (loss, new_state), grads = jax.value_and_grad(loss_fn, has_aux=True)(train_state.params)\n",
    "        updates, new_opt_state = self.optimizers.update(\n",
    "            grads, train_state.opt_state, train_state.params)\n",
    "        new_params = optax.apply_updates(train_state.params, updates)\n",
    "        return TrainState(\n",
    "            epoch=train_state.epoch,\n",
    "            step=train_state.step + 1,\n",
    "            params=new_params,\n",
    "            state=new_state,\n",
    "            opt_state=new_opt_state,\n",
    "            next_key=next_key,\n",
    "            logs={'train/loss': loss}\n",
    "        )\n",
    "    \n",
    "    def val_step(self, train_state: TrainState, batch: Tuple[jax.Array, ...]) -> TrainState:\n",
    "        inputs, labels = batch\n",
    "        rng_key, next_key = jrand.split(train_state.next_key)\n",
    "        logits, _ = self.transformed.apply(\n",
    "            train_state.params, train_state.state,\n",
    "            rng_key, # <== rng\n",
    "            inputs, is_training=False # <== inputs\n",
    "        )\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits, labels).mean()\n",
    "        acc = (jnp.argmax(logits, axis=-1) == labels).mean()\n",
    "        logs = {'val/loss': loss, \"val/accuracy\": acc}\n",
    "\n",
    "        return train_state._replace(\n",
    "            step=train_state.step + 1,\n",
    "            next_key=next_key, logs=logs\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Callback:\n",
    "    _trainer: Trainer = None\n",
    "\n",
    "    @property\n",
    "    def trainer(self) -> Trainer: \n",
    "        return self._trainer\n",
    "\n",
    "    @trainer.setter\n",
    "    def trainer(self, trainer: Trainer): \n",
    "        self._trainer = trainer\n",
    "    \n",
    "    def init_trainer(self, trainer: Trainer) -> Callback:\n",
    "        self.trainer = trainer\n",
    "        return self\n",
    "\n",
    "    def on_epoch_begin(self, state: TrainState): pass\n",
    "\n",
    "    def on_epoch_end(self, state: TrainState): pass\n",
    "\n",
    "    def on_train_batch_begin(self, state: TrainState): pass\n",
    "\n",
    "    def on_train_batch_end(self, state: TrainState): pass\n",
    "\n",
    "    def on_train_begin(self, state: TrainState): pass\n",
    "\n",
    "    def on_train_end(self, state: TrainState): pass\n",
    "\n",
    "    def on_val_batch_begin(self, state: TrainState): pass\n",
    "\n",
    "    def on_val_batch_end(self, state: TrainState): pass\n",
    "\n",
    "    def on_val_begin(self, state: TrainState): pass\n",
    "\n",
    "    def on_val_end(self, state: TrainState): pass\n",
    "    \n",
    "    # __all__ = [\n",
    "    #     \"on_epoch_begin\",\n",
    "    #     \"on_epoch_end\",\n",
    "    #     \"on_predict_batch_begin\",\n",
    "    #     \"on_predict_batch_end\",\n",
    "    #     \"on_predict_begin\",\n",
    "    #     \"on_predict_end\",\n",
    "    #     \"on_test_batch_begin\",\n",
    "    #     \"on_test_batch_end\",\n",
    "    #     \"on_test_begin\",\n",
    "    #     \"on_test_end\",\n",
    "    #     \"on_train_batch_begin\",\n",
    "    #     \"on_train_batch_end\",\n",
    "    #     \"on_train_begin\",\n",
    "    #     \"on_train_end\",\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CallbackList:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        callbacks: List[Callback] = None,\n",
    "        add_history: bool = True,\n",
    "        add_progbar: bool = True,\n",
    "        trainer: Trainer = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.callbacks = callbacks if callbacks else []\n",
    "        self._check_callbacks()\n",
    "        self._add_default_callbacks(add_history, add_progbar)\n",
    "\n",
    "        if trainer is not None:\n",
    "            self.init_trainer(trainer)\n",
    "\n",
    "    def append(self, callback: Callback):\n",
    "        self.callbacks.append(callback)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.callbacks)\n",
    "\n",
    "    def _check_callbacks(self):\n",
    "        for cb in self.callbacks:\n",
    "            if not isinstance(cb, Callback):\n",
    "                raise TypeError(\n",
    "                    \"All callbacks must be instances of `Callback` \"\n",
    "                    f\"got {type(cb).__name__}.\"\n",
    "                )\n",
    "\n",
    "    def _add_default_callbacks(self, add_history: bool, add_progbar: bool):\n",
    "        pass\n",
    "\n",
    "    def init_trainer(self, trainer: Trainer):\n",
    "        for callback in self.callbacks:\n",
    "            callback.init_trainer(trainer)\n",
    "        \n",
    "    def _call_hook(self, hook_name, state):\n",
    "        for callback in self.callbacks:\n",
    "            batch_hook = getattr(callback, hook_name)\n",
    "            batch_hook(state)\n",
    "\n",
    "    def on_epoch_begin(self, state: TrainState):\n",
    "        self._call_hook(\"on_epoch_begin\", state)\n",
    "\n",
    "    def on_epoch_end(self, state: TrainState):\n",
    "        self._call_hook(\"on_epoch_end\", state)\n",
    "\n",
    "    def on_train_batch_begin(self, state: TrainState):\n",
    "        self._call_hook(\"on_train_batch_begin\", state)\n",
    "\n",
    "    def on_train_batch_end(self, state: TrainState):\n",
    "        self._call_hook(\"on_train_batch_end\", state)\n",
    "\n",
    "    def on_train_begin(self, state: TrainState):\n",
    "        self._call_hook(\"on_train_begin\", state)\n",
    "\n",
    "    def on_train_end(self, state: TrainState):\n",
    "        self._call_hook(\"on_train_end\", state)\n",
    "\n",
    "    def on_val_batch_begin(self, state: TrainState):\n",
    "        self._call_hook(\"on_val_batch_begin\", state)\n",
    "\n",
    "    def on_val_batch_end(self, state: TrainState):\n",
    "        self._call_hook(\"on_val_batch_end\", state)\n",
    "\n",
    "    def on_val_begin(self, state: TrainState):\n",
    "        self._call_hook(\"on_val_begin\", state)\n",
    "\n",
    "    def on_val_end(self, state: TrainState):\n",
    "        self._call_hook(\"on_val_end\", state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def make_hk_module(output_size: int = 2):\n",
    "    \"\"\"Creates a Haiku module with a linear layer and batchnorm.\"\"\"\n",
    "    def model(x, is_training=True):\n",
    "        return hk.BatchNorm(True, True, 0.9)(\n",
    "            hk.Linear(output_size)(x), is_training=is_training)\n",
    "    \n",
    "    return hk.transform_with_state(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = make_hk_module()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax_dataloader import DataLoader, ArrayDataset\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "xs, ys = make_classification(n_samples=2000, n_features=10, random_state=0)\n",
    "train_ds = ArrayDataset(xs[:1500], ys[:1500])\n",
    "test_ds = ArrayDataset(xs[1500:], ys[1500:])\n",
    "train_dl = DataLoader(train_ds, 'jax', batch_size=128)\n",
    "test_dl = DataLoader(test_ds, 'jax', batch_size=128)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountCallback(Callback):\n",
    "    on_epoch_begin_count = 0\n",
    "    on_epoch_end_count = 0\n",
    "    on_train_batch_begin_count = 0\n",
    "    on_train_batch_end_count = 0\n",
    "    on_train_begin_count = 0\n",
    "    on_train_end_count = 0\n",
    "    on_val_batch_begin_count = 0\n",
    "    on_val_batch_end_count = 0\n",
    "    on_val_begin_count = 0\n",
    "    on_val_end_count = 0\n",
    "\n",
    "    def on_epoch_begin(self, state: TrainState):\n",
    "        self.on_epoch_begin_count += 1\n",
    "    \n",
    "    def on_epoch_end(self, state: TrainState):\n",
    "        self.on_epoch_end_count += 1\n",
    "\n",
    "    def on_train_batch_begin(self, state: TrainState):\n",
    "        self.on_train_batch_begin_count += 1\n",
    "\n",
    "    def on_train_batch_end(self, state: TrainState):\n",
    "        self.on_train_batch_end_count += 1\n",
    "\n",
    "    def on_train_begin(self, state: TrainState):\n",
    "        self.on_train_begin_count += 1\n",
    "\n",
    "    def on_train_end(self, state: TrainState):\n",
    "        self.on_train_end_count += 1\n",
    "\n",
    "    def on_val_batch_begin(self, state: TrainState):\n",
    "        self.on_val_batch_begin_count += 1\n",
    "\n",
    "    def on_val_batch_end(self, state: TrainState):\n",
    "        self.on_val_batch_end_count += 1\n",
    "\n",
    "    def on_val_begin(self, state: TrainState):\n",
    "        self.on_val_begin_count += 1\n",
    "\n",
    "    def on_val_end(self, state: TrainState):\n",
    "        self.on_val_end_count += 1\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CountCallback()\n",
    "trainer = Trainer(\n",
    "    transformed=module,\n",
    "    optimizers=optax.adam(1e-3),\n",
    "    callbacks=[cb],\n",
    "    n_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/mambaforge-pypy3/envs/dev/lib/python3.9/site-packages/haiku/_src/base.py:515: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  param = init(shape, dtype)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test trainer properties\n",
    "assert trainer.num_train_batches == len(train_dl)\n",
    "assert trainer.num_train_steps == len(train_dl) * trainer.n_epochs\n",
    "assert trainer.num_val_batches == len(test_dl)\n",
    "assert trainer.num_val_steps == len(test_dl) * trainer.n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test callback\n",
    "assert cb.on_epoch_begin_count == trainer.n_epochs\n",
    "assert cb.on_epoch_end_count == trainer.n_epochs\n",
    "assert cb.on_train_batch_begin_count == trainer.num_train_steps\n",
    "assert cb.on_train_batch_end_count == trainer.num_train_steps\n",
    "assert cb.on_train_begin_count == 1\n",
    "assert cb.on_train_end_count == 1\n",
    "assert cb.on_val_batch_begin_count == trainer.num_val_steps\n",
    "assert cb.on_val_batch_end_count == trainer.num_val_steps\n",
    "assert cb.on_val_begin_count == trainer.n_epochs\n",
    "assert cb.on_val_end_count == trainer.n_epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
